---
title: "大模型使用工具调用（函数调用）"
date: 2024-08-23
draft: false
tags: ["LangChain", "Tool-Calling", "Function-Calling"]
---


# 什么是工具调用

顾名思义，就是使得我们的代码流程能调用函数。在某些地方，函数也作为工具，因此也称工具调用（Tool Calling）。函数调用中，LLM 的难点在于根据用户 `query` 去选择哪个函数，以及对应函数的参数分别是什么。

值得注意的是，大模型并不会帮你去调用工具，而只是返回应当调用什么工具以及对应工具的参数。工具的执行链路是在本地完成的。本文中会出现 FunctionCalling 以及 ToolCalling 两个概念，主要和代码相对应。目前而言感觉理解上不需要进行区分。


# Function-Calling

首先，假设我们有两个函数 `add_two_numbers` 和 `multi_two_numbers`，我们需要为这两个函数进行一些描述，如下：
```python
def add_two_numbers(a, b):
    return a + b


def multi_two_numbers(a, b):
    return a * b


name2funcs = {
    "add_two_numbers": add_two_numbers,
    "multi_two_numbers": multi_two_numbers,
}

functions = [
    {
        "name": "add_two_numbers",
        "description": "given numbers a and b, return a + b",
        "parameters": {
            "type": "object",
            "properties": {
                "a": {"type": "integer", "description": "the first number"},
                "b": {"type": "integer", "description": "the second number"},
            },
        },
    },
    {
        "name": "multi_two_numbers",
        "description": "given numbers a and b, return a * b",
        "parameters": {
            "type": "object",
            "properties": {
                "a": {"type": "integer", "description": "the first number"},
                "b": {"type": "integer", "description": "the second number"},
            },
        },
    },
]
```

## 使用 OpenAI

首先，我们使用 OpenAI 最原始的接口观察当需要调用函数时候，大模型返回了什么信息：

```python
import os
from openai import OpenAI


client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"), base_url=os.getenv("OPENAI_BASE_URL")
)

query = "4 + 3等于多少"
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": query}],
    functions=functions,
    function_call="auto",
)

print(response)
```

上述代码的输出为
```python
ChatCompletion(id='chatcmpl-9xtqMrX8AQsjcM5Ztlma9A5wFbOQt', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=FunctionCall(arguments='{"a":4,"b":3}', name='add_two_numbers'), tool_calls=None))], created=1724063042, model='gpt-35-turbo', object='chat.completion', service_tier=None, system_fingerprint='fp_e49e4201a9', usage=CompletionUsage(completion_tokens=19, prompt_tokens=115, total_tokens=134))
```

值得注意的是，对于其中的 `function_call=FunctionCall(arguments='{"a":4,"b":3}', name='add_two_numbers')` 字段，不同的 query 有不同的结果，以下是一些示例：
```python
query = "4 + 3 + 8等于多少"
function_call=FunctionCall(arguments='{"a":4,"b":3}', name='add_two_numbers')

query = "4 + （3 + 8）等于多少"
function_call=FunctionCall(arguments='{"a":4,"b":11}')

query = "4 + 3 * 8等于多少"
function_call=FunctionCall(arguments='{"a":4,"b":{"b":3}}')
function_call=FunctionCall(arguments='{"a":3,"b":8}')
```

可以发现，对于需要嵌套调用 functions 的情况，解析的结果是不一定准确的。这一点即使将模型换成 `gpt-4o` 也无法很好地解决这个问题。

## 通过 LangChain 使用 LLM 的 Function-Call 功能
LangChain 中也对 OpenAI 的接口做了一次封装，在有调用时，返回的 `message.additional_kwargs` 中记录了相关的函数调用信息。

```python
import json
from langchain.schema import HumanMessage, FunctionMessage
from langchain_openai import ChatOpenAI


llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

query = "4 + 3等于多少"
messages = [HumanMessage(content=query)]
message = llm.predict_messages(messages, functions=functions)

while message.additional_kwargs:
	function_name = message.additional_kwargs["function_call"]["name"]
	arguments = json.loads(message.additional_kwargs["function_call"]["arguments"])
	
	# 调用工具并获取结果
	print(f"Calling function {function_name} with arguments {arguments}")
	function_response = name2funcs[function_name](**arguments)
	messages.append(FunctionMessage(name=function_name, content=function_response))
	message = llm.predict_messages(messages=messages, functions=functions)

print(message.content)
```

## 使用 LangChain 将 Tools 绑定到 LLM 中

```python
from langchain_core.messages import HumanMessage, ToolMessage
from langchain_core.tools import tool
from langchain.schema import HumanMessage
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)


@tool
def add_two_numbers(a, b):
    """
    计算两个数的求和

    Args:
        a: 加数
        b: 被加数
    """
    return a + b


@tool
def multi_two_numbers(a, b):
    """
    计算两个数的乘积

    Args:
        a: 乘数
        b: 被乘数
    """
    return a * b


tools = [add_two_numbers, multi_two_numbers]
name2funcs = {
    "add_two_numbers": add_two_numbers,
    "multi_two_numbers": multi_two_numbers,
}
llm_with_tools = llm.bind_tools(tools)

query = "3+4等于多少"
messages = [HumanMessage(query)]
ai_msg = llm_with_tools.invoke(messages)
messages.append(ai_msg)

print(ai_msg)

for tool_call in ai_msg.tool_calls:
    print(f">>> 开始调用工具：{tool_call['name']}({tool_call['args']})")
    selected_tool = name2funcs[tool_call["name"].lower()]

    tool_output = selected_tool.invoke(tool_call["args"])
    messages.append(ToolMessage(tool_output, tool_call_id=tool_call["id"]))

final_msg = llm_with_tools.invoke(messages)
print(final_msg.content)

```

此方式使用 `tool` 装饰器，要求被装饰的函数必须有 `docstring`，否则会有 `ValueError: Function must have a docstring if description not provided.` 此错误。`docstring` 为对应工具提供了说明。


# Tool-Calling
这部分是使用 OpenAI 的 Function-Calling 的深入部分。

## 初探 tool-calling
上面的 function-calling 中，可以发现返回的结果中除了 function_call 还有一个 tool_calls，于是也顺带看了一下如何使用：

```python
tools = [
    {
        "type": "function",
        "function": {
            "name": "add_two_numbers",
            "description": "given numbers a and b, return a + b",
            "parameters": {
                "type": "object",
                "properties": {
                    "a": {"type": "integer", "description": "the first number"},
                    "b": {"type": "integer", "description": "the second number"},
                },
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "multi_two_numbers",
            "description": "given numbers a and b, return a * b",
            "parameters": {
                "type": "object",
                "properties": {
                    "a": {"type": "integer", "description": "the first number"},
                    "b": {"type": "integer", "description": "the second number"},
                },
            },
        },
    },
]

query = "4 + 3等于多少"
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": query}],
    tools=tools,
)

print(response)
```
返回的回答为：
```python
ChatCompletion(id='chatcmpl-9yaYQcXwyTxLxQU5OS0gAZRKiliUb', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3SRixIWWkkfxgABz1vgJLK1p', function=Function(arguments='{"a":4,"b":3}', name='add_two_numbers'), type='function')]))], created=1724227222, model='gpt-35-turbo', object='chat.completion', system_fingerprint='fp_e49e4201a9', usage=CompletionUsage(completion_tokens=19, prompt_tokens=115, total_tokens=134))
```
可以看到其中的 function_call=None，但是 tool_calls 有内容。但是这当中不禁引起了我的好奇
- 函数调用看上去和工具调用功能差不多，为啥要同时存在？
- 工具调用叫 tool_calls 而函数调用叫 function_call，复数表示的含义是什么？

关于第二点，我重复试了一下 `4 + 3 * 8` 这个 case，出来的结果为：
```python
tool_calls=[ChatCompletionMessageToolCall(id='call_k7ZZbho2Pycxun1Sdg2xBbxx', function=Function(arguments='{"a": 4, "b": 3}', name='add_two_numbers'), type='function'), ChatCompletionMessageToolCall(id='call_IJmmZEjDXQnUJfzsQeVZxGRI', function=Function(arguments='{"a": 3, "b": 8}', name='multi_two_numbers'), type='function')]))]
```
虽然结果依然不准确，但是是能识别出有多个工具调用。这个时候，就能发现对于 `4 + 3 和 5 * 9 的结果是多少` 这个问题，采用 tool_calling 能解决问题，而使用 function_call 只能返回一个函数调用。

## 使用 tool_calling 进行多次工具调用
```python
name2funcs = {
    "add_two_numbers": lambda a, b: a + b,
    "multi_two_numbers": lambda a, b: a * b,
}


query = "4 + 3 和 5 * 9 的结果是多少"

messages = [
    {"role": "system", "content": "你是一个数学计算大师"},
    {"role": "user", "content": query},
]

while True:
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        tools=tools,
    )

    messages.append(response.choices[0].message)

    finish_reason = response.choices[0].finish_reason

    if finish_reason == "stop":
        break

    tool_calls = response.choices[0].message.tool_calls

    # 进行工具调用并将结果以 tool 的形式加到 messages 中
    for tool_call in tool_calls:
        func = name2funcs[tool_call.function.name]
        func_args = json.loads(tool_call.function.arguments)
        func_output = func(**func_args)

        messages.append(
            {
                "tool_call_id": tool_call.id,
                "role": "tool",
                "name": tool_call.function.name,
                "content": str(func_output),
            }
        )
print(messages[-1].content)
```

进行 `tool_calling` 的时候，可以通过 `response.choices[0].finish_reason` 判断当前返回的内容是需要进行工具/函数调用还是结束了。最终，程序输出的结果为：4 + 3 的结果是 7，5 * 9 的结果是 45。在此 demo 中，需要保证 `name2funcs` 中的函数的参数和 tools 中的参数要一致，因为 `tool_call.function.arguments` 中返回的信息是 `dict` 类型。

## 有依赖的工具调用
在 function-calling 部分讨论了 "4 + 3 * 8 等于多少",值得注意的是，使用多次工具调用的时候，可能会触发这个 bug：
```
Traceback (most recent call last):
  File "demo.py", line 70, in <module>
    func = name2funcs[tool_call.function.name]
KeyError: 'multi_tool_use.parallel'
```

即使程序运行成功，得到的结果往往也是不对的，会得到最终结果为 31，因为计算了 4 + 3 和 3 * 8，最后求和结果为 31，可见当前对于这种情况不是很好解决。

# 总结
本文对大模型的 Function-Calling 和 Tool-Calling 进行了用法介绍，同时进行了一些案例分析。
# 参考内容
- [LangChain tool_calling](https://python.langchain.com/v0.2/docs/how_to/tool_calling/)
- [GPT function calling v2](https://zhuanlan.zhihu.com/p/675565746)

